{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Scott Huang: Analysis, Conceptualization, Writing – review & editing\n",
    "- Ye Teng: Background research, Visualization, Writing – review & editing\n",
    "- Cathy: Project Administration, Software, Writing - original draft\n",
    "- Fei Liang: Experiential Investigation, Writing - original draft\n",
    "- Rich: Data curation, Methodology, Writing – review & editing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which product attributes such as price, customer ratings, number of reviews, and brand—are most strongly associated with dietary supplement sales on e-commerce platforms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dietary supplements are a growing part of the health and wellness market, and many consumers now buy products such as vitamins, protein powders, and probiotics through e-commerce platforms. Unlike prescription medications, dietary supplements are not strictly regulated before they are sold, which means consumers often rely on visible product information when making purchasing decisions.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Because of this, attributes such as price, brand reputation, and especially online reviews play an important role in shaping supplement sales online.\n",
    "\n",
    "Previous research on online shopping behavior has consistently shown that customer ratings and reviews have a strong influence on product sales. Chevalier and Mayzlin found that products with higher ratings and more positive reviews tend to sell better, particularly when consumers cannot easily evaluate product quality before purchase.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) This highlights how social proof becomes more important when buyers face uncertainty, which is often the case for health-related products like dietary supplements.\n",
    "\n",
    "Beyond reviews, brand reputation also plays a key role in consumer decision-making. Prior research suggests that in online marketplaces with many similar products, consumers often rely on brand identity and reputation as signals of quality and reliability.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) This project builds on prior work by examining how price, customer ratings, number of reviews, and brand are associated with actual dietary supplement sales on e-commerce platforms, using observed sales data rather than self-reported preferences.\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) U.S. Food & Drug Administration. Dietary Supplements.\n",
    "https://www.fda.gov/food/dietary-supplements\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2)Chevalier, J. A., & Mayzlin, D. (2006). The effect of word of mouth on sales: Online book reviews. Journal of Marketing Research, 43(3), 345–354. https://www.jstor.org/stable/30162409?seq=1 \n",
    "\n",
    "3. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Clemons, E. K., Gao, G. G., & Hitt, L. M. (2006). When online reviews meet hyperdifferentiation. Journal of Management Information Systems, 23(2), 149–171.  https://www.tandfonline.com/doi/abs/10.2753/MIS0742-1222230207\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that price, customer ratings, review count, and brand are significantly associated with dietary supplement sales. Specifically, we expect review count and average rating to be positively associated with sales, price to be negatively associated with sales, and sales to differ across brands. Among these attributes, we hypothesize that review count will exhibit the strongest positive association with sales. We define “sales” as either total units sold, revenue generated, or sales rank, depending on data availability.\n",
    "\n",
    "We believe that consumer purchasing decisions on e-commerce platforms are strongly influenced by social proof and credibility. In particular, the number of reviews may serve as an indicator of product popularity and trustworthiness, making consumers more likely to purchase items that appear widely used or endorsed by others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "**Unit of observation:** Amazon product listing (ideally one row per ASIN).  \n",
    "**Primary dataset:** Kaggle “Amazon Products Sales Dataset 42K+ Items – 2025” (product-level snapshot).  \n",
    "**Outcome (DV):** sales-performance proxy such as BSR / rank (lower rank = better sales).  \n",
    "**Key predictors (IVs):** price, rating_avg, review_count, discount (if available), brand, category/subcategory.  \n",
    "**Controls / derived variables (as needed):** category dummies, log(review_count), and optionally price-per-serving if servings/size can be parsed.  \n",
    "**Supplementary dataset (optional):** Amazon Reviews’23 (McAuley Lab) to validate or reconstruct rating_avg/review_count and optionally derive review-text features.\n",
    "\n",
    "**Why these data fit the project:** They directly contain (or allow construction of) variables describing product attributes and popularity/sales proxy, enabling us to test relationships between attributes (pricing, ratings, brand/category) and sales performance.\n",
    "\n",
    "**Main constraints:** outcome is a proxy (not true sales), coverage may be incomplete, and some columns may be noisy or missing; we will report missingness, apply cleaning rules, and run robustness checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading airline-safety.csv:   0%|          | 0.00/1.23k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress:  50%|█████     | 1/2 [00:00<00:00,  6.08it/s]   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: airline-safety.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading bad-drivers.csv:   0%|          | 0.00/1.37k [00:00<?, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:00<00:00,  9.89it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: bad-drivers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1: Amazon Products Sales Dataset (42K+ Items, 2025) — Kaggle\n",
    "\n",
    "**Dataset name / source:** “Amazon Products Sales Dataset 42K+ Items – 2025” (Kaggle)  \n",
    "**Access method:** Download CSV from Kaggle (record dataset version + download date in our repo)\n",
    "\n",
    "**What it contains (high-level):**  \n",
    "This dataset provides a product-level snapshot for ~42K Amazon listings. While exact column names may vary by version, fields typically include product title/name, category/subcategory, brand, current price (and sometimes list price/discount), average rating, review count, and one or more ranking / “bestseller” indicators that can be used as a sales-performance proxy.\n",
    "\n",
    "**Planned variables (from this dataset):**\n",
    "- **Outcome (sales performance proxy):** BSR / ranking field (lower is better), or a closely related ranking/bestseller indicator if BSR is not present.\n",
    "- **Predictors:** price, discount (if available), rating_avg, review_count, brand, category/subcategory.\n",
    "- **Potential controls / derived variables:** standardized category dummies; log(review_count); price-per-serving (only if size/servings can be parsed).\n",
    "\n",
    "**Unit of observation:**  \n",
    "Product listing (ideally one row per ASIN). If duplicates exist, we will deduplicate by ASIN, or by (title, brand) rules when ASIN is unavailable.\n",
    "\n",
    "**Known/expected issues & cleaning (plan):**\n",
    "- **Price formatting:** prices often include currency symbols/commas → strip and convert to numeric.\n",
    "- **Missingness:** drop rows missing key fields (outcome + core predictors) or impute only when appropriate; report missingness summary.\n",
    "- **Outliers:** inspect extreme price/rank values; use robust methods and/or winsorize/clip for sensitivity checks.\n",
    "- **Duplicates:** remove duplicates by ASIN or (title, brand) + category where needed.\n",
    "- **Category filtering (project-specific):** filter to supplement/health-related categories if our research question focuses on supplements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 (optional): Amazon Reviews’23 — McAuley Lab (UCSD)\n",
    "\n",
    "**Dataset name / source:** Amazon Reviews’23 (McAuley Lab, UCSD)  \n",
    "**Access method:** Use the public release / Hugging Face dataset card (download only relevant category subsets)\n",
    "\n",
    "**What it contains (high-level):**  \n",
    "Large-scale review-level data including star ratings, review text, timestamps, and product identifiers (e.g., ASIN). Depending on the subset, it may also include product metadata files (category, title, brand, etc.).\n",
    "\n",
    "**How we would use it (if needed):**\n",
    "- Validate or reconstruct **rating_avg** and **review_count** for products in our analysis using review-level aggregation.\n",
    "- Optionally derive review-text features (e.g., sentiment/topic indicators) if that supports our research question.\n",
    "\n",
    "**Join key:**  \n",
    "ASIN (preferred). If Dataset #1 does not include ASIN, we will avoid unreliable fuzzy matching unless absolutely necessary.\n",
    "\n",
    "**Known limitations:**\n",
    "- Very large files → restrict to relevant categories and/or a manageable sample.\n",
    "- Coverage mismatch vs Kaggle snapshot → treat as supplementary rather than primary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access & reproducibility\n",
    "\n",
    "We will download the Kaggle dataset as a CSV file and store it in our project repository (or a shared drive) with a clear filename that includes the dataset version and download date. If we use Amazon Reviews’23, we will document which category subset(s) we downloaded and the date/version of the release. We will keep all cleaning steps in a reproducible notebook/script, and we will record any filtering decisions (e.g., category filters) so our results can be replicated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References / access (last checked 2026-02-18)\n",
    "\n",
    "- Kaggle: **Amazon Products Sales Dataset 42K+ Items – 2025**  \n",
    "  https://www.kaggle.com/datasets/ikramshah512/amazon-products-sales-dataset-42k-items-2025\n",
    "\n",
    "- **Amazon Reviews’23 (McAuley Lab, UCSD)** project page  \n",
    "  https://amazon-reviews-2023.github.io/\n",
    "\n",
    "- Hugging Face dataset card: **McAuley-Lab / Amazon-Reviews-2023**  \n",
    "  https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> Our data will be reviews and ratings on the platforms, which are publicly available. We are not dealing with individual human subjects and asking for their consent. When they submitted the review, they understood that their reviews would be publicly available. So informed consent is not neccessary in this project. \n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> There are some bias that could be introduced in the data collection process. Products with more sales are likely to get more reviews. People are more likely to leave a review if their experience if really positive/negative. There could even be fake reivews from the seller trying to boost sales. We will try to find a way of normalizing reviews and minimize the bias mentioned above. \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> We will collect all the data anonymously and neglect all the PII (e.g. account name, email). We will also only collect the reviews and rating of the product and not use any other irrelevant information.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> We will ensure the results don't favor any groups over others unfairly. It will be clearly stated that this project studies the nature of consumer behaviors based on ratings, reviews, and sales of dietary supplements rather than their actual medical effectiveness.\n",
    "\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> Since the data would be public available already and we are not doing any new data collection ourselves, there will not be any measures used to protect or secure data.\n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> There are no data directly collected from any individual in the data collection process, and there will not be any personal information included.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> There is currently no plan to delete the local copy of the data we obtain. However, it is unlikely that we ever use the data for any other purposes in the future. It is possible that we will have a data retention plan after we have completed the project and the data is no longer needed.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Due to the nature of this project, the analysis is more likely to reflect trends in customers' purchasing behaviors rather than the true health benefits of the supplements. We will clearly state the the limitations in the analysis in the report so the users are aware.\n",
    " \n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> Besides the bias already mentioned in the data collection part, there are some other potential bias in the dataset. There might be a significant difference in sales and rating/reviews across different categories of supplements. There could also be temporal bias, where older products recieve more reviews over time. We will address these bias by comparing supplements by category and normalize the effetcs of temporal bias.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> Our visualizations and summary statistics will be presented in the sole purpose of helping the readers understand the data more intuitively and represent the underlying data. The representations will be closely related to the focus of the projects and will not contain any irrelevant or distracting information.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We will ensure that no data with PII will be used in the project. We do not need any PII for the purpose of the project so any data related to PII would be removed in the data cleaning process.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> The process of generating the analysis will be well documented throughout the project and presented in our final report. It will be documented step by step in detail such that the analysis is reproducible if we ever need to conduct the same analysis again. \n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> We ensure that the data does not rely on variables or proxies that are unfairly discriminatory. The data will only be characteristics about the products (ratings, reviews, sales, etc.) and not of specific individuals and gourps. The results will not be used for discriminatory purposes.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    "> We will separate the supplements into groups to test the resutls. The performance will be evaluated over different groupings such as categories, price tiers, and etc.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> We will use more metrics than simply sales prediction accuracy. There will also be multiple evaluation metrics considered (RMSE, correlation, etc.) and results will be compared for performances. \n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "> We will choose a balanced model and that incorporates performance and interpretability. All features used in the models will be explained, and the decision making process would be clear.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> The limitation of the project will be clearly communicated in the report. We will elaborate the shorcomings and bias briefly mentioned in this section in the final report so the reader can clearly understand the limitations and apply the findings of the study as how it is intended to be. We will state that state that the project will invetigate consumer behavior rather than supplement effectiveness. \n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> We will monitor the model through sample predictions randomly selected from the platform.\n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> If any users are harmed by the model, we will go back and analyze the reason for the unintended harm, and revise (modifying features or model) to prevent similar problems in the future.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> If at any point we find a roll back is needed, we will removed the results of the project immediately to minimize effects.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> As stated earlier, we will clearly state the limitations of this project so users understand the purpose of the project clearly and use the results accordingly. We curretly do not have a plan to monitor these.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Team Expectation 1*\n",
    "* Our team will primarily communicate through WeChat for updates, questions, and storing documents and datasets.\n",
    "* *Team Expectation 2*\n",
    "* We will assume that all feedback is well-intentioned and aimed at improving the project. Team members are encouraged to speak up if they disagree or have concerns.\n",
    "* *Team Expecation 3*\n",
    "* All team members are expected to contribute equally across the entire project in terms of effort. If a member is struggling to complete a task, they are expected to notify the group as soon as possible. The team will work together to redistribute tasks if needed.\n",
    "* *Team Expectation 4*\n",
    "* If issues arise regarding participation or communication, we will first address them respectfully within the group through written or verbal communication. If a member continues to fail to meet expectations after being notified, we will follow course policy and escalate the issue to the professor.\n",
    "* *Team Expectation 5*\n",
    "* If the team cannot reach an agreement on a minor decision after discussion (e.g., formatting or visualization style), we will first attempt a majority vote. If a quick resolution is needed, we may use a neutral random decision method (such as a coin flip or random spinner) to ensure fairness and keep the project moving forward. Major decisions related to the dataset selection or analysis methods will require group agreement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "January 29, 6:30 PM Completed (Good Job)\n",
    "\n",
    "Completed before meeting: Reviewed an example project on fast food access and disease rates.\n",
    "Discuss at meeting: Summarized the project; Discussed strengths, weaknesses, and limitations (multicollinearity, confounding, small sample size); Identified lessons to apply to our own project, including being transparent about limitations.\n",
    "\n",
    "February 4 6:30PM  Completed (Good Job)\n",
    "\n",
    "Completed before meeting: Review final project checklist and course requirements; Review and finalize the research question and variables.\n",
    "Discuss at meeting: Confirm project scope and research question; Align on outcome variable (sales or sales rank) and predictor variables (price, ratings, number of reviews, brand); Assign initial roles.\n",
    "\n",
    "February 9   6:30PM  Completed (Good Job)\n",
    "\n",
    "Completed before meeting: Conduct background research on dietary supplements and ecommerce consumer behavior; Identify 1–2 relevant prior studies or articles.\n",
    "Discuss at meeting: Discuss background context and prior work; Decide which sources to cite; Refine and finalize the hypothesis.\n",
    "\n",
    "February 12 6:30PM  Completed (Good Job)\n",
    "\n",
    "Completed before meeting: Identify and explore potential datasets; Review dataset features, size, and limitations.\n",
    "Discuss at meeting: Finalize dataset selection; Discuss data limitations; Draft the Dataset(s) section.\n",
    "\n",
    "February 16 6:30PM Completed (Good Job)\n",
    "\n",
    "Completed before meeting: Import dataset; Perform initial data cleaning (handle missing values, convert variable types).\n",
    "Discuss at meeting: Review data cleaning decisions; Decide how to handle outliers; Confirm the dataset is clean and usable.\n",
    "\n",
    "February 20 6:30PM \n",
    "Completed before meeting: Conduct exploratory data analysis (EDA); Create preliminary visualizations showing relationships between product attributes and sales.\n",
    "Discuss at meeting: Interpret EDA results; Decide which visualizations to include in the final project.\n",
    "\n",
    "February 25 6:30PM\n",
    "Completed before meeting: Perform correlation and regression analyses; Save analysis outputs.\n",
    "Discuss at meeting: Interpret analysis results; Discuss associations between variables; Emphasize correlation versus causation.\n",
    "\n",
    "March 2 6:30PM\n",
    "Completed before meeting: Draft the Ethics and Bias section; Identify potential ethical concerns and sources of bias in the data.\n",
    "Discuss at meeting: Review ethical considerations; Discuss how bias and limitations are addressed in the analysis.\n",
    "\n",
    "March 6 6:30PM\n",
    "Completed before meeting: Draft the Conclusion and Discussion sections.\n",
    "Discuss at meeting: Edit and refine conclusions; Ensure the research question is clearly answered.\n",
    "\n",
    "March 10 6:30PM\n",
    "Completed before meeting: Combine all sections into a complete project notebook draft.\n",
    "Discuss at meeting: Full project review; Edit for clarity, organization, and narrative flow.\n",
    "\n",
    "March 16 6:30PM\n",
    "Completed before meeting: Prepare the project video script and select key visualizations.\n",
    "Discuss at meeting: Practice and refine video explanation\n",
    "\n",
    "March 18 6:30PM\n",
    "Completed before meeting: Final proofreading\n",
    "Discuss at meeting: Submit Final Project and Group Project Survey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
